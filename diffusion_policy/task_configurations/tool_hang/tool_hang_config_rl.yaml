_target_: diffusion_policy.workspace.train_diffusion_rl_lowdim_workspace.TrainRLWorkspace
action_dim: 10
obs_dim: 53

# Policy configuration
policy:
  checkpoint_path: /home/luca_daniel/tum-adlr-04/data/outputs/tool_hang/hparams_12/unet/checkpoints/latest.ckpt
  model_config:
    action_dim: 10
    obs_dim: 53
    horizon: 16
    n_action_steps: 3
    n_obs_steps: 3
    obs_as_global_cond: true
    obs_as_local_cond: false

# Task configuration
task:
  env_runner:
    _target_: diffusion_policy.env_runner.robomimic_lowdim_runner_rl.RobomimicLowdimRunnerRL
    abs_action: true
    dataset_path: data/robomimic/datasets/tool_hang/ph/low_dim_abs.hdf5
    max_steps: 700
    n_action_steps: 3
    n_obs_steps: 3
    n_envs: 28
    obs_keys:
      - object
      - robot0_eef_pos
      - robot0_eef_quat
      - robot0_gripper_qpos
    render_hw: [128, 128]

# Training configuration
training:
  device: cuda:0
  seed: 42
  num_epochs: 1000
  steps_per_epoch: 1000
  eval_every: 5
  eval_episodes: 10

# Logging configuration
logging:
  mode: online
  project: tool-hang-rl
  name: ppo_refinement
  tags:
    - tool_hang
    - ppo
    - rl_refinement