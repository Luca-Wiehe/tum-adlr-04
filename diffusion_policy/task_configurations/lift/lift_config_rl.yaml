_target_: diffusion_policy.workspace.train_diffusion_rl_lowdim_workspace.TrainRLWorkspace
action_dim: 10
obs_dim: 19
diffusion_ckpt: /home/luca_daniel/tum-adlr-04/outputs/diffusion_ckpt/epoch=0099-test_mean_score=0.700.ckpt

# Policy configuration
policy:
  _target_: diffusion_policy.policy.diffusion_cond_mlp_lowdim_policy.DiffusionCondMLPLowdimPolicy
  action_dim: 10
  obs_dim: 19
  horizon: 16
  n_action_steps: 3
  n_obs_steps: 3
  obs_as_global_cond: true
  obs_as_local_cond: false
  model:
    _target_: diffusion_policy.model.diffusion.conditional_mlp.ConditionalMLP
    cond_predict_scale: true
    diffusion_step_embed_dim: 256
    cond_dim: 57
    input_dim: 10
  noise_scheduler:
    _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
    beta_end: 0.02
    beta_schedule: squaredcos_cap_v2
    beta_start: 0.0001
    clip_sample: true
    num_train_timesteps: 100
    prediction_type: epsilon
    variance_type: fixed_small

# Task configuration
task:
  env_runner:
    _target_: diffusion_policy.env_runner.robomimic_lowdim_runner_rl.RobomimicLowdimRunnerRL
    device: cuda:0
    abs_action: true
    dataset_path: data/robomimic/datasets/lift/ph/low_dim_abs.hdf5
    obs_keys:
    - object
    - robot0_eef_pos
    - robot0_eef_quat
    - robot0_gripper_qpos
    action_dim: 10
    n_obs_steps: 3
    n_action_steps: 3
    total_timesteps: 400

# Training configuration
training:
  device: cuda:0
  seed: 42
  num_epochs: 1000
  steps_per_epoch: 1000
  checkpoint_every: 20
  eval_every: 25
  eval_episodes: 25

# Logging configuration
logging:
  mode: online
  project: lift-rl
  name: ppo_refinement
  tags:
    - lift
    - ppo
    - rl_refinement