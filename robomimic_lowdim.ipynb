{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this notebook to document Robomimic Lowdim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to answer: \n",
    "+ What are the most important imports/files that this module makes use of?\n",
    "+ What are the inputs? \n",
    "+ What are the outputs? \n",
    "+ How to initialize? \n",
    "+ How to start a visualization? \n",
    "+ Where is the model used?\n",
    "+ What kind of experiments are conducted with lowdim?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowdim Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Initialize class using `RobomimicLowdimWrapper()` as described in `robomimic_lowdim_wrapper.py`\n",
    "+ OpenAI Gym Simulation environment\n",
    "    + `.seed(seed)`  sets seed to create environment\n",
    "    + `.step(action)` performs next action and returns `observation`, `reward`, `done`, `info`\n",
    "    + `.reset()` resets the environment (observation), possible to reset to set seed\n",
    "    + `.get_observation()` returns the current observation\n",
    "+ An observation has the following attributes:\n",
    "    + `object`: \n",
    "    + `pos`: position of the robot\n",
    "    + `qpos`: joint positions of the robot\n",
    "    + `quat`: quaternion of the robot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowdim Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize class using `RobomimicLowdimPolicy()` as described in `robomimic_lowdim_policy.py`\n",
    "+ Inherits from `BaseImagePolicy` class as defined in `base_image_policy.py` which has the following key properties:\n",
    "    + `predict_action(obs_dict)`: Function stub to predict the next action given the observation\n",
    "    + `reset()`: Function stub to reset the policy\n",
    "    + `set_normalizer()`: Function stub to set the policy's normalizer\n",
    "+ Extends `BaseLowdimPolicy`\n",
    "    + For initialization\n",
    "        + `get_robo_mimic_config()`: Creates a config file for robomimic based on algorithm, observation type, task, and dataset type\n",
    "        + `algo_factory()`: Initializes a model for the given algorithm based on config file and available actions\n",
    "    + For training\n",
    "        + `train_on_batch()`: Uses observations and actions. Preprocesses a robomimic batch and calls `model.train()` to train the model\n",
    "        + `get_optimizer()`: optimize policy after based on previous policy\n",
    "    + For inference\n",
    "        + `predict_action()`: Predicts the next action given the observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowdim Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize class using `RobomimicLowdimRunner(**lowdimRunner_cfg, output_dir)` as described `robomimic_lowdim_runner.py`. Example usage is given in `test_robomimic_image_runner.py`.\n",
    "+ Inherits from `BaseImageRunner` class as defined in `base_lowdim_runner.py` which has the following key properties:\n",
    "    + `run()`: Function stub to run the policy\n",
    "    + `save()`: Function stub to save the policy\n",
    "    + `load()`: Function stub to load the policy\n",
    "+ Extends `BaseLowdimRunner`\n",
    "    + For initialization\n",
    "        + initializes configuration attributes and paths\n",
    "        + wraps `RobomimicLowdimWrapper` in a `VideoRecordingWrapper` to generate output videos\n",
    "    + For training\n",
    "        + initializes output directory\n",
    "        + configures path for rendered output videos\n",
    "    + For running\n",
    "        + Locates video data and divides it into chunks\n",
    "        + For each chunk, reset policy and observations\n",
    "        + Then, run the simulator (i.e. obtain `action_dict` and call `.step()` until `done` for all chunks)\n",
    "        + Use `env.render()` to add video paths to the output\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
